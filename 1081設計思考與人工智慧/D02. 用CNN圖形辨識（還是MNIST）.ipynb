{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann LeCun 被譽為 Deep Learning 的三巨頭之一。他的 CNN (Convolutional Neural Networks) 是讓 Neural Network 重新受到重視的主因之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 初始準備\n",
    "\n",
    "基本上和之前是一樣的, 我們就不再說明。\n",
    "\n",
    "    %env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 讀入 MNIST 數據庫\n",
    "\n",
    "### 由 Keras 讀入 MNIST\n",
    "\n",
    "基本上和我們上次一樣, 這次因為 Keras 已偷偷把數據庫存在你的電腦, 所以會快很多!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸入格式整理\n",
    "\n",
    "如果你還記得, 我們每筆輸入資料都是 28x28 的陣列, CNN 其實就是吃「圖」的, 所以基本上不用像之前把每筆資料拉平。「但。是。」平常的圖都有 R, G, B 三個 channels, 每個 channel 都是一個矩陣, 也就是一張圖可能是三個矩陣! 我們是灰階, 也就是只有一個 channel。但這件事也要明確的告訴 Keras。\n",
    "\n",
    "換句話說, 我們的輸入每筆資料型式要從 (28, 28) 換成 (28, 28, 1)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 要的是 (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認一下..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原來 28x28 矩陣..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd04212bcf8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X,  cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出格式整理\n",
    "\n",
    "和上次一樣, 我們用標準 1-hot 方式處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3 打造你的 CNN\n",
    "\n",
    "### 決定神經網路架構、讀入相關套件\n",
    "\n",
    "CNN 我們一樣要決定用幾層的 CNN, 然後是不是每次都要做 max-pooling。再來就是拉平、送入標準神經網路 (再度要決定幾層、幾個神經元)。\n",
    "\n",
    "我們上課的時候, 同學建議要做 3 次的 convolution + max-pooling, filter 大小都是 $5\\times 5$。\n",
    "\n",
    "* 做 <span style=\"color:red;\">3</span> 次 convolution, 每次都接 max-pooling\n",
    "* filter 大小都是 <span style=\"color:red;\">5x5</span>, max-pooling 都用 <span style=\"color:red;\">2x2</span> 為一小區塊\n",
    "\n",
    "CNN 一個小技巧是每層的 filters 數目是越來越多, 上課同學建議第一層 4 個, 因為要做三次, 所以我們 filters 數分別是 <span style=\"color:red;\">4, 8, 16</span>。做完 convolution 之後, 我們要拉平、再送入一個標準的神經網路。這個神經網路設計是這樣:\n",
    "\n",
    "* 只有 <span style=\"color:red;\">1</span> 個隱藏層, 使用 <span style=\"color:red;\">9</span> 個神經元 (這也是同學建議)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構我們的神經網路\n",
    "\n",
    "一開始一樣是打開個空白的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一個隱藏層一樣要告訴 Keras 我們輸入長什麼樣子。`padding` 設成 `same` 是每個 filter 會輸出原來 28x28 一樣大小的矩陣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(4, (5, 5), padding='same', input_shape=(28, 28, 1),\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(8, (5, 5), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再 Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (5, 5), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling 最終回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然後我們要送進一般的神經網路了。記得這是要拉平的, 還在 Keras 會幫我們做!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(9, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出和上次一樣!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 組裝\n",
    "\n",
    "和之前比較不一樣的是我們還要做 `compile` 才正式把我們的神經網路建好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=\"categorical_crossentropy\",\n",
    "#              optimizer=Adadelta(),\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.07), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視我們的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 4)         104       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 8)         808       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 16)          3216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 1305      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                100       \n",
      "=================================================================\n",
      "Total params: 5,533\n",
      "Trainable params: 5,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0900 - accuracy: 0.1516\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0898 - accuracy: 0.1879\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0895 - accuracy: 0.2251\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0890 - accuracy: 0.2616\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0876 - accuracy: 0.3181\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0796 - accuracy: 0.3860\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0619 - accuracy: 0.4920\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0517 - accuracy: 0.5772\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0407 - accuracy: 0.7031\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0332 - accuracy: 0.7576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd050fdacc0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡因為第一次訓練有點遜 (CNN 標準), 所以我再執行 `fit` 一次, 因此實際上是訓練了 20 次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2-5 結果測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分數\n",
    "\n",
    "我們來看測試資料 (我們的 CNN 沒看過的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 131us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看成績, 順便用 Python 3.6 開始的 f-string format 方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的 loss: 0.02980\n",
      "測試資料的正確率: 0.7824000120162964\n"
     ]
    }
   ],
   "source": [
    "print(f'測試資料的 loss: {score[0]:.5f}')\n",
    "print(f'測試資料的正確率: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 儲存結果\n",
    "\n",
    "結果看來還不差, 所以我們把結果存起來。上次我們介紹分別存架構和權重的方法, 這次我們看看怎麼樣一次就存入權重 + 結構!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 欣賞一下成果\n",
    "\n",
    "我們示範一下怎麼讀回我們的神經網路。你會發現讀回來之後就可以直接使用了!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先把我們原來的 model 刪掉, 保證接下來的是讀進來的。我們要用一個 `load_model` 的函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們用另一個方式: 每次選 5 個顯示, 看是不是有正確辨識。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看來真的可以直接用!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pick = np.random.randint(1,9999, 5)\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(x_test[pick[i]].reshape(28,28), cmap='Greys')\n",
    "    plt.title(predict[pick[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結論\n",
    "\n",
    "我們到此, 基本上是「亂做」的神經網路。有些同學在不斷試驗的過程中, 可能會發現有時會出現很糟糕的結果。因此, 接下來我們要介紹怎麼樣用些簡單的手法, 能讓學習效果比較穩定, 而且有可能可以增加學習效率。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
