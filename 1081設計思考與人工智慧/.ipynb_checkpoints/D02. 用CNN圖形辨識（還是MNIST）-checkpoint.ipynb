{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann LeCun 被譽為 Deep Learning 的三巨頭之一。他的 CNN (Convolutional Neural Networks) 是讓 Neural Network 重新受到重視的主因之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 初始準備\n",
    "\n",
    "基本上和之前是一樣的, 我們就不再說明。\n",
    "\n",
    "    %env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 讀入 MNIST 數據庫\n",
    "\n",
    "### 由 Keras 讀入 MNIST\n",
    "\n",
    "基本上和我們上次一樣, 這次因為 Keras 已偷偷把數據庫存在你的電腦, 所以會快很多!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸入格式整理\n",
    "\n",
    "如果你還記得, 我們每筆輸入資料都是 28x28 的陣列, CNN 其實就是吃「圖」的, 所以基本上不用像之前把每筆資料拉平。「但。是。」平常的圖都有 R, G, B 三個 channels, 每個 channel 都是一個矩陣, 也就是一張圖可能是三個矩陣! 我們是灰階, 也就是只有一個 channel。但這件事也要明確的告訴 Keras。\n",
    "\n",
    "換句話說, 我們的輸入每筆資料型式要從 (28, 28) 換成 (28, 28, 1)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 要的是 (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認一下..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原來 28x28 矩陣..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb39fbb6668>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X,  cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出格式整理\n",
    "\n",
    "和上次一樣, 我們用標準 1-hot 方式處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3 打造你的 CNN\n",
    "\n",
    "### 決定神經網路架構、讀入相關套件\n",
    "\n",
    "CNN 我們一樣要決定用幾層的 CNN, 然後是不是每次都要做 max-pooling。再來就是拉平、送入標準神經網路 (再度要決定幾層、幾個神經元)。\n",
    "\n",
    "我們上課的時候說過, 我們準備要做 3 次的 convolution + max-pooling, filter 大小都是 $3\\times 3$。\n",
    "\n",
    "* 做 <span style=\"color:red;\">3</span> 次 convolution, 每次都接 max-pooling\n",
    "* filter 大小都是 <span style=\"color:red;\">3x3</span>, max-pooling 都用 <span style=\"color:red;\">2x2</span> 為一小區塊\n",
    "\n",
    "CNN 一個小技巧是每層的 filters 數目是越來越多, 上課同學建議第一層 4 個, 因為要做三次, 所以我們 filters 數分別是 <span style=\"color:red;\">4, 8, 16</span>。做完 convolution 之後, 我們要拉平、再送入一個標準的神經網路。這個神經網路設計是這樣:\n",
    "\n",
    "* 只有 <span style=\"color:red;\">2</span> 個隱藏層, 分別使用 <span style=\"color:red;\">17, 33</span> 個神經元 (這也是同學建議)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構我們的神經網路\n",
    "\n",
    "一開始一樣是打開個空白的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一個隱藏層一樣要告訴 Keras 我們輸入長什麼樣子。`padding` 設成 `same` 是每個 filter 會輸出原來 28x28 一樣大小的矩陣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(4, (3, 3), padding='same', input_shape=(28, 28, 1),\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(8, (3, 3), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再 Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3, 3), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling 最終回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然後我們要送進一般的神經網路了。記得這是要拉平的, 還在 Keras 會幫我們做!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(17, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(33, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出和上次一樣!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 組裝\n",
    "\n",
    "和之前比較不一樣的是我們還要做 `compile` 才正式把我們的神經網路建好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=\"categorical_crossentropy\",\n",
    "#              optimizer=Adadelta(),\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yenlung/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.07), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視我們的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                2465      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 33)                594       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                340       \n",
      "=================================================================\n",
      "Total params: 4,903\n",
      "Trainable params: 4,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yenlung/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yenlung/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0898 - acc: 0.1024\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0895 - acc: 0.1378\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0892 - acc: 0.2062\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0886 - acc: 0.2903\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0871 - acc: 0.3583\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0782 - acc: 0.3898\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0495 - acc: 0.6630\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0347 - acc: 0.7654\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0287 - acc: 0.8070\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0255 - acc: 0.8276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb3a09a4588>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡因為第一次訓練有點遜 (CNN 標準), 所以我再執行 `fit` 一次, 因此實際上是訓練了 20 次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2-5 結果測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分數\n",
    "\n",
    "我們來看測試資料 (我們的 CNN 沒看過的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 39us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看成績, 順便用 Python 3.6 開始的 f-string format 方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的 loss: 0.02402\n",
      "測試資料的正確率: 0.8376\n"
     ]
    }
   ],
   "source": [
    "print(f'測試資料的 loss: {score[0]:.5f}')\n",
    "print(f'測試資料的正確率: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 儲存結果\n",
    "\n",
    "結果看來還不差, 所以我們把結果存起來。上次我們介紹分別存架構和權重的方法, 這次我們看看怎麼樣一次就存入權重 + 結構!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 欣賞一下成果\n",
    "\n",
    "我們示範一下怎麼讀回我們的神經網路。你會發現讀回來之後就可以直接使用了!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先把我們原來的 model 刪掉, 保證接下來的是讀進來的。我們要用一個 `load_model` 的函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們用另一個方式: 每次選 5 個顯示, 看是不是有正確辨識。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看來真的可以直接用!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pick = np.random.randint(1,9999, 5)\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(x_test[pick[i]].reshape(28,28), cmap='Greys')\n",
    "    plt.title(predict[pick[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結論\n",
    "\n",
    "我們到此, 基本上是「亂做」的神經網路。有些同學在不斷試驗的過程中, 可能會發現有時會出現很糟糕的結果。因此, 接下來我們要介紹怎麼樣用些簡單的手法, 能讓學習效果比較穩定, 而且有可能可以增加學習效率。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
